{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFXGEYkkcodd"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp, expr\n",
        "\n",
        "# Create sample sales data\n",
        "media_data = {\n",
        "    \"post_id\": [101, 102,103, 104,105],\n",
        "    \"user_id\": [1,2,3,4,5],\n",
        "    \"location\": [\"USA\", \"UK\", \"Canada\", \"Australia\",\"China\"],\n",
        "    \"confident_score\": [0.85,0.9,0.75,0.7,0.95],\n",
        "}\n",
        "# Convert to DataFrame\n",
        "df_social_media = pd.DataFrame(media_data)\n",
        "# Save as CSV\n",
        "csv_path = \"/dbfs/FileStore/media_data.csv\"\n",
        "df_social_media.to_csv(csv_path, index=False)\n",
        "print(\"CSV file created successfully.\")\n",
        "# Save as Parquet\n",
        "parquet_path = \"/dbfs/FileStore/media_data.parquet\"\n",
        "df_social_media.to_parquet(parquet_path, index=False)\n",
        "print(f\"Sample data saved to {csv_path} and {parquet_path}\")\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Social Media Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load data from CSV\n",
        "df_sales = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .load(\"/FileStore/social_media.csv\")\n",
        "\n",
        "# Write transformed data to Delta table\n",
        "delta_table_path = \"/delta/social_media\"\n",
        "df_social_media.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
        "print(\"Delta table created and data written successfully.\")\n",
        "\n",
        "# Create a live table for incoming social media posts\n",
        "# Make sure the correct path is used for the streaming source\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE LIVE TABLE social_media AS\n",
        "SELECT * FROM streaming.`/mnt/streaming/social_media`;\n",
        "\"\"\")\n",
        "\n",
        "# Create a user-defined function for sentiment analysis\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "# Initialize the sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define UDF for sentiment analysis\n",
        "@udf(FloatType())\n",
        "def sentiment_udf(text):\n",
        "    return analyzer.polarity_scores(text)['compound']\n",
        "\n",
        "# Create a live table to compute sentiment scores\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE STREAMING LIVE TABLE sentiment_analysis AS\n",
        "SELECT\n",
        "    post_id,\n",
        "    user_id,\n",
        "    location,\n",
        "    confident_score AS sentiment_score\n",
        "FROM media_data;\n",
        "\"\"\")\n",
        "\n",
        "# Read from Kafka stream (ensure the Kafka topic is correct)\n",
        "social_media_stream = (\n",
        "    spark.readStream\n",
        "    .format(\"kafka\")\n",
        "    .option(\"kafka.bootstrap.servers\", \"your_kafka_server:port\")\n",
        "    .option(\"subscribe\", \"social_media_topic\")\n",
        "    .load()\n",
        ")\n",
        "\n",
        "# Convert Kafka stream to DataFrame\n",
        "social_media_posts = social_media_stream.selectExpr(\"CAST(value AS STRING) as json_value\")\n",
        "\n",
        "# Further transform the JSON data into a structured DataFrame (adjust schema as necessary)\n",
        "social_media_posts_df = social_media_posts.select(\n",
        "    expr(\"json_value.post_id\").alias(\"post_id\"),\n",
        "    expr(\"json_value.user_id\").alias(\"user_id\"),\n",
        "    expr(\"json_value.post_text\").alias(\"post_text\")\n",
        ")\n",
        "\n",
        "# Write the streaming DataFrame to Delta table\n",
        "query = (\n",
        "    social_media_posts_df\n",
        "    .writeStream\n",
        "    .format(\"delta\")\n",
        "    .outputMode(\"append\")\n",
        "    .option(\"checkpointLocation\", \"/mnt/checkpoints/sentiment_analysis\")\n",
        "    .table(\"sentiment_analysis\")\n",
        ")\n",
        "\n",
        "# Start the query\n",
        "query.awaitTermination()\n"
      ]
    }
  ]
}