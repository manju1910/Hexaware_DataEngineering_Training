{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VoktpiwAo8e",
        "outputId": "d6ead6de-f77a-41e8-c724-681b627be69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     post_id     user_id  username    location  followers_count  \\\n",
            "101        1    john_doe  New York         USA              500   \n",
            "102        2  jane_smith    London          UK             1200   \n",
            "103        3  mike_brown   Toronto      Canada              900   \n",
            "104        4  alice_wong    Sydney   Australia             1500   \n",
            "105        5     lucy_li   Beijing       China              700   \n",
            "\n",
            "    profile_creation_date                                  post_content  \\\n",
            "101            2022-01-15               Loving the new product release!   \n",
            "102            2020-06-25        This service is terrible, never again.   \n",
            "103            2021-05-10  The update feels just okay, nothing special.   \n",
            "104            2019-11-20        The best app I’ve used in a long time!   \n",
            "105            2023-03-05   I am really disappointed with this service.   \n",
            "\n",
            "      post_date   platform  sentiment_score_id sentiment_type  \\\n",
            "101  2024-09-18    Twitter                   1       positive   \n",
            "102  2024-09-19   Facebook                   2       negative   \n",
            "103  2024-09-20  Instagram                   3        neutral   \n",
            "104  2024-09-18   LinkedIn                   4       positive   \n",
            "105  2024-09-19    Twitter                   5       negative   \n",
            "\n",
            "     confidence_score  \n",
            "101              0.85  \n",
            "102              0.90  \n",
            "103              0.75  \n",
            "104              0.70  \n",
            "105              0.95  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the social media posts from the CSV file\n",
        "df = pd.read_csv('/content/social media.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.DATA PREPROCCESSING"
      ],
      "metadata": {
        "id": "OcDNwBysF1FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/social media.csv')\n",
        "\n",
        "# Step 1: Handle Missing or Null Values\n",
        "df.fillna('', inplace=True)\n",
        "\n",
        "# Step 2: Convert Dates to Datetime Format\n",
        "df['post_date'] = pd.to_datetime(df['post_date'], format='%Y-%m-%d')\n",
        "df['profile_creation_date'] = pd.to_datetime(df['profile_creation_date'], format='%Y-%m-%d')\n",
        "\n",
        "# Step 3: Normalize Text Data\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    return text\n",
        "\n",
        "df['post_content_cleaned'] = df['post_content'].apply(clean_text)\n",
        "\n",
        "# Step 4: Handle Categorical Features\n",
        "df = pd.get_dummies(df, columns=['platform', 'sentiment_type'], drop_first=True)\n",
        "\n",
        "# Step 5: Feature Scaling\n",
        "scaler = MinMaxScaler()\n",
        "df[['followers_count', 'confidence_score']] = scaler.fit_transform(df[['followers_count', 'confidence_score']])\n",
        "\n",
        "# Step 6: Tokenization and Text Vectorization\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df['post_content_cleaned'])\n",
        "X_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Combine the vectorized text data with the original DataFrame\n",
        "df = pd.concat([df, X_df], axis=1)\n",
        "\n",
        "# Step 7: Save Preprocessed Data\n",
        "df.to_csv('Preprocessed_SocialMediaData.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the preprocessed DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "D4M0keKeC3BB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cba627-da7c-4923-cc60-d22886a4f3de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     post_id     user_id  username    location  followers_count  \\\n",
            "101      1.0    john_doe  New York         USA         0.038462   \n",
            "102      2.0  jane_smith    London          UK         0.307692   \n",
            "103      3.0  mike_brown   Toronto      Canada         0.192308   \n",
            "104      4.0  alice_wong    Sydney   Australia         0.423077   \n",
            "105      5.0     lucy_li   Beijing       China         0.115385   \n",
            "\n",
            "    profile_creation_date                                  post_content  \\\n",
            "101            2022-01-15               Loving the new product release!   \n",
            "102            2020-06-25        This service is terrible, never again.   \n",
            "103            2021-05-10  The update feels just okay, nothing special.   \n",
            "104            2019-11-20        The best app I’ve used in a long time!   \n",
            "105            2023-03-05   I am really disappointed with this service.   \n",
            "\n",
            "     post_date  sentiment_score_id  confidence_score  ... this time  to  \\\n",
            "101 2024-09-18                 1.0          0.714286  ...  NaN  NaN NaN   \n",
            "102 2024-09-19                 2.0          0.857143  ...  NaN  NaN NaN   \n",
            "103 2024-09-20                 3.0          0.428571  ...  NaN  NaN NaN   \n",
            "104 2024-09-18                 4.0          0.285714  ...  NaN  NaN NaN   \n",
            "105 2024-09-19                 5.0          1.000000  ...  NaN  NaN NaN   \n",
            "\n",
            "    update used  ve  way  with  worth  would  \n",
            "101    NaN  NaN NaN  NaN   NaN    NaN    NaN  \n",
            "102    NaN  NaN NaN  NaN   NaN    NaN    NaN  \n",
            "103    NaN  NaN NaN  NaN   NaN    NaN    NaN  \n",
            "104    NaN  NaN NaN  NaN   NaN    NaN    NaN  \n",
            "105    NaN  NaN NaN  NaN   NaN    NaN    NaN  \n",
            "\n",
            "[5 rows x 71 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.SENTIMENT ANALYSIS"
      ],
      "metadata": {
        "id": "vpt3gVUlGDm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "df = pd.read_csv('Preprocessed_SocialMediaData.csv')\n",
        "\n",
        "# Ensure all values in post_content_cleaned are strings\n",
        "df['post_content_cleaned'] = df['post_content_cleaned'].astype(str)\n",
        "\n",
        "# Function to analyze sentiment using TextBlob\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity\n",
        "\n",
        "# Apply the sentiment analysis function to the cleaned post content\n",
        "df['sentiment_score'] = df['post_content_cleaned'].apply(analyze_sentiment)\n",
        "\n",
        "# Classify sentiment based on the polarity score\n",
        "def classify_sentiment(score):\n",
        "    if score > 0:\n",
        "        return 'positive'\n",
        "    elif score < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df['sentiment_class'] = df['sentiment_score'].apply(classify_sentiment)\n",
        "\n",
        "# Display the updated DataFrame with sentiment scores\n",
        "print(df[['post_content', 'sentiment_score', 'sentiment_class']].head())\n",
        "\n",
        "# Save the DataFrame with sentiment scores to a new CSV file\n",
        "df.to_csv('SocialMediaData_WithSentiment.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t8Q_4WdFta7",
        "outputId": "605a005d-fa1d-4b44-bdbe-79f4c8277b58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   post_content  sentiment_score  \\\n",
            "0               Loving the new product release!         0.368182   \n",
            "1        This service is terrible, never again.        -1.000000   \n",
            "2  The update feels just okay, nothing special.         0.428571   \n",
            "3        The best app I’ve used in a long time!         0.475000   \n",
            "4   I am really disappointed with this service.        -0.750000   \n",
            "\n",
            "  sentiment_class  \n",
            "0        positive  \n",
            "1        negative  \n",
            "2        positive  \n",
            "3        positive  \n",
            "4        negative  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.FEATURE ENGINEERING"
      ],
      "metadata": {
        "id": "vApGV_URGaTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Preprocessed_SocialMediaData.csv')\n",
        "\n",
        "# Ensure all values in post_content are strings\n",
        "df['post_content'] = df['post_content'].astype(str)\n",
        "\n",
        "# Function to extract hashtags\n",
        "def extract_hashtags(text):\n",
        "    hashtags = re.findall(r'#\\w+', text)\n",
        "    return ', '.join(hashtags)  # Join multiple hashtags into a single string\n",
        "\n",
        "# Function to extract keywords (e.g., words with more than 4 characters)\n",
        "def extract_keywords(text):\n",
        "    words = re.findall(r'\\w+', text)\n",
        "    keywords = [word for word in words if len(word) > 4]  # Customize the length as needed\n",
        "    return ', '.join(keywords)\n",
        "\n",
        "# Apply the functions to extract hashtags and keywords\n",
        "df['hashtags'] = df['post_content'].apply(extract_hashtags)\n",
        "df['keywords'] = df['post_content'].apply(extract_keywords)\n",
        "\n",
        "# Optionally: Count the number of hashtags and keywords\n",
        "df['hashtag_count'] = df['hashtags'].apply(lambda x: len(x.split(', ')) if x else 0)\n",
        "df['keyword_count'] = df['keywords'].apply(lambda x: len(x.split(', ')) if x else 0)\n",
        "\n",
        "# Display the updated DataFrame with new features\n",
        "print(df[['post_content', 'hashtags', 'keywords', 'hashtag_count', 'keyword_count']].head())\n",
        "\n",
        "# Save the DataFrame with new features to a new CSV file\n",
        "df.to_csv('SocialMediaData_WithFeatures.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsNuqonSGGU6",
        "outputId": "9630f756-f3fe-4f2b-8653-3f80d03b405f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   post_content hashtags  \\\n",
            "0               Loving the new product release!            \n",
            "1        This service is terrible, never again.            \n",
            "2  The update feels just okay, nothing special.            \n",
            "3        The best app I’ve used in a long time!            \n",
            "4   I am really disappointed with this service.            \n",
            "\n",
            "                          keywords  hashtag_count  keyword_count  \n",
            "0         Loving, product, release              0              3  \n",
            "1  service, terrible, never, again              0              4  \n",
            "2  update, feels, nothing, special              0              4  \n",
            "3                                               0              0  \n",
            "4    really, disappointed, service              0              3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ioFVAo3CGc4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}